{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Processing\n",
    "\n",
    "##### 1.1 X-y split.\n",
    "\n",
    "In order to do the X-y split, we need to figure out the inputs and outputs of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# Find more information about the dataset\n",
    "df = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "#print(df.info())\n",
    "#print(df.shape)\n",
    "#print(df.columns)\n",
    "\n",
    "# Run the transformations from the previous lab\n",
    "\n",
    "# 1. Standardize column names\n",
    "df.rename(columns = {'EmploymentStatus': 'Employment Status'}, inplace = True)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# 2. Remove columns that are highly correlated to each other\n",
    "df.drop(['policy', 'vehicle size'], axis=1, inplace=True)\n",
    "\n",
    "#print(len(df['effective to date'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that the `total claim amount` is the output we're looking to predict, as for an insurance policy company it would be relevant to know which customer type is more likely to make claims - so that they can perhaps change the insurance policy pricing for customers that would be considered \"high-risk\", i.e. more likely to make claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df['total claim amount'])\n",
    "X = df.drop('total claim amount', axis=1)\n",
    "\n",
    "# Check that the operations ran correctly\n",
    "#print(y.columns)\n",
    "#print(X.columns)\n",
    "\n",
    "# Change y column to numerical data\n",
    "y = y.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Normalize (numerical).\n",
    "\n",
    "We need to separate the numerical columns in X from the categorical columns so we can normalize the data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=np.number)\n",
    "\n",
    "# Check that we have selected the correct data\n",
    "#print(X_num.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize the data using `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum and maximum for each column of the dataframe:\n",
    "transformer = MinMaxScaler().fit(X_num) \n",
    "\n",
    "# Find out what the transformer is:\n",
    "#print(type(transformer))\n",
    "\n",
    "# Show the maximum across all columns (mainly to see what the info in the transformer):\n",
    "#print(transformer.data_max_)\n",
    "\n",
    "# Normalize the data (or transform):\n",
    "x_minmax = transformer.transform(X_num)\n",
    "#print(type(x_minmax))\n",
    "#print(x_minmax.shape)\n",
    "\n",
    "# Transform the numpy array into the normalized dataframe \n",
    "X_num_norm = pd.DataFrame(x_minmax, columns=X_num.columns)\n",
    "#print(X_num_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. One Hot/Label Encoding (categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the categorical values\n",
    "X_cat = X.select_dtypes(include='object')\n",
    "X_cat.drop(['customer', 'effective to date'], axis=1, inplace=True)\n",
    "\n",
    "# Check that we selected the right data\n",
    "#print(X_cat.info())\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "encoder.fit(X_cat)\n",
    "#print(type(encoder.categories_))\n",
    "#print(encoder.get_feature_names_out())\n",
    "\n",
    "# Extract the encoded array from the encoder\n",
    "encoded = encoder.transform(X_cat).toarray()\n",
    "#print(type(encoded))\n",
    "\n",
    "# Transform the numpy array to a Pandas dataframe\n",
    "cat_encoded = pd.DataFrame(encoded)\n",
    "\n",
    "# Add column names to the dataframe\n",
    "cat_encoded.columns = encoder.get_feature_names_out()\n",
    "\n",
    "# Check the encoded dataframe\n",
    "#print(cat_encoded.head())\n",
    "#print(len(encoder.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. Concat DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_num_norm, cat_encoded], axis=1)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Linear Regression\n",
    "\n",
    "##### 2.1. Train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Apply linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions before describing the model:\n",
    "predictions  = model.predict(X_test)\n",
    "\n",
    "# Learn more about the predictions:\n",
    "#print(predictions.shape)\n",
    "#print(type(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model Validation\n",
    "\n",
    "Description: R2, MSE, RMSE, MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "MAE = np.mean(abs(y_test.to_numpy() - predictions))\n",
    "\n",
    "print(\"r2 = \", r2)\n",
    "print(\"RMSE = \", RMSE)\n",
    "print(\"MSE = \", MSE)\n",
    "print(\"MAE = \", MAE)\n",
    "\n",
    "median_total_claim = np.median(y_test.to_numpy())\n",
    "print(\"Median Total Claim = \", median_total_claim)\n",
    "\n",
    "print(RMSE * 100 / median_total_claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r2 score is relatively high, which means that the model is decent at predicting the total claim value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelling\n",
    "\n",
    "Try to improve the linear regression model. We'll try the following methods to improve the model:\n",
    "\n",
    "1. Remove the outliers in the numerical data.\n",
    "2. Try the Box-Cox method on columns with more than 200 unique values.\n",
    "3. Try the Box-Cox method on columns with more than 500 unique values.\n",
    "4. Remove the outliers in the numerical data & apply the 2. and 3. Box-Cox methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will firstly create functions to run all of the steps we did previously for the linear\n",
    "# regression, so we can easily re-run the model when using different methods:\n",
    "\n",
    "def split_data(df):\n",
    "    y = df['total claim amount']\n",
    "    y = y.apply(pd.to_numeric, errors='ignore')\n",
    "    X = df.drop('total claim amount', axis=1)\n",
    "    X_num = X.select_dtypes(include=np.number)\n",
    "    X_cat = X.select_dtypes(include='object')\n",
    "    return X, y, X_num, X_cat\n",
    "\n",
    "def normalize_data(X_num):\n",
    "    transformer = MinMaxScaler().fit(X_num) \n",
    "    x_minmax = transformer.transform(X_num)\n",
    "    X_num_norm = pd.DataFrame(x_minmax, columns=X_num.columns)\n",
    "    return X_num_norm\n",
    "\n",
    "def encode_data(X_cat):\n",
    "    X_cat.drop(['customer', 'effective to date'], axis=1, inplace=True)\n",
    "    encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "    encoder.fit(X_cat)\n",
    "    encoded = encoder.transform(X_cat).toarray()\n",
    "    cat_encoded = pd.DataFrame(encoded)\n",
    "    cat_encoded.columns = encoder.get_feature_names_out()\n",
    "    return cat_encoded\n",
    "\n",
    "def run_regression(X_num_norm, cat_encoded, y):\n",
    "    X = pd.concat([X_num_norm, cat_encoded], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions  = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "    MSE = mean_squared_error(y_test, predictions)\n",
    "    MAE = np.mean(abs(y_test.to_numpy() - predictions))\n",
    "    print(\"r2 = \", r2)\n",
    "    print(\"RMSE = \", RMSE)\n",
    "    print(\"MSE = \", MSE)\n",
    "    print(\"MAE = \", MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=1.5, in_columns=df.select_dtypes(np.number).columns, \n",
    "                    skip_columns=[]):\n",
    "    for column in in_columns:\n",
    "        if column not in skip_columns:\n",
    "            upper = np.percentile(df[column], 75)\n",
    "            lower = np.percentile(df[column], 25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df\n",
    "\n",
    "df1 = df.copy()\n",
    "df1 = remove_outliers(df1, in_columns=df1.select_dtypes(np.number).columns, \n",
    "                         skip_columns=['number of open complaints', 'number of policies',\n",
    "                         'months since policy inception', 'months since last claim']) \n",
    "\n",
    "X1, y1, X1_num, X1_cat = split_data(df1)\n",
    "X1_num_norm = normalize_data(X1_num)\n",
    "cat1_encoded = encode_data(X1_cat)\n",
    "run_regression(X1_num_norm, cat1_encoded, y1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that the model ran slightly better after removing the outliers.\n",
    "\n",
    "#### 4.2. Box Cox transformation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply the Box Cox transformation, we need to use data that is: positive & non-constant.\n",
    "# Therefore, we need to apply it only on columns that don't have discrete values\n",
    "# and clean those columns from negative values\n",
    "\n",
    "# Copy & split the dataframe\n",
    "df2 = df.copy()\n",
    "X2, y2, X2_num, X2_cat = split_data(df2)\n",
    "\n",
    "# We should look at the number of unique values in each column:\n",
    "for column in X2_num:\n",
    "    print(column, len(X2_num[column].unique()))\n",
    "\n",
    "# We can see that customer lifetime value, income and monthly premium auto seem to be \n",
    "# non-discrete values. However, the latter seems to have only 202 unique values, so we will\n",
    "# try the Box Cox tranformation with and without it.\n",
    "\n",
    "# Box Cox transformation includes monthly premium auto\n",
    "for column in X2_num:\n",
    "    # Select the columns with continuous data\n",
    "    if len(X2_num[column].unique()) > 200:\n",
    "        # Replace negative data with null values, then replace those with the mean\n",
    "        X2_num[column] = np.where(X2_num[column]<=0, np.nan, X2_num[column])        \n",
    "        X2_num[column] = X2_num[column].fillna(X2_num[column].mean())\n",
    "        X2_num[column], _ = stats.boxcox(X2_num[column])\n",
    "\n",
    "X2_num_norm = normalize_data(X2_num)\n",
    "cat2_encoded = encode_data(X2_cat)\n",
    "run_regression(X2_num_norm, cat2_encoded, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model performs worse when the Box Cox transformation was applied to all three columns.\n",
    "\n",
    "#### 4.3. Box Cox transformation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy & split the dataframe\n",
    "df3 = df.copy()\n",
    "X3, y3, X3_num, X3_cat = split_data(df3)\n",
    "\n",
    "# Box Cox transformation excludes monthly premium auto\n",
    "for column in X3_num:\n",
    "    # Select the columns with continuous data\n",
    "    if len(X3_num[column].unique()) > 500:\n",
    "        # Replace negative data with null values, then replace those with the mean\n",
    "        X3_num[column] = np.where(X3_num[column]<=0, np.nan, X3_num[column])        \n",
    "        X3_num[column] = X3_num[column].fillna(X3_num[column].mean())\n",
    "        X3_num[column], _ = stats.boxcox(X3_num[column])\n",
    "\n",
    "X3_num_norm = normalize_data(X3_num)\n",
    "cat3_encoded = encode_data(X3_cat)\n",
    "run_regression(X3_num_norm, cat3_encoded, y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs roughly the same with and without the Box Cox transformation 2.\n",
    "\n",
    "#### 4.4. Remove outliers + Box Cox transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy & split the dataframe\n",
    "df4 = df.copy()\n",
    "df4 = remove_outliers(df4, in_columns=df4.select_dtypes(np.number).columns, \n",
    "                         skip_columns=['number of open complaints', 'number of policies',\n",
    "                         'months since policy inception', 'months since last claim']) \n",
    "X4, y4, X4_num, X4_cat = split_data(df4)\n",
    "\n",
    "# Box Cox transformation includes monthly premium auto\n",
    "for column in X4_num:\n",
    "    # Select the columns with continuous data\n",
    "    if len(X4_num[column].unique()) > 200:\n",
    "        # Replace negative data with null values, then replace those with the mean\n",
    "        X4_num[column] = np.where(X4_num[column]<=0, np.nan, X4_num[column])        \n",
    "        X4_num[column] = X4_num[column].fillna(X4_num[column].mean())\n",
    "        X4_num[column], _ = stats.boxcox(X4_num[column])\n",
    "\n",
    "X4_num_norm = normalize_data(X4_num)\n",
    "cat4_encoded = encode_data(X4_cat)\n",
    "run_regression(X4_num_norm, cat4_encoded, y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs better when removing the outliers before doing the Box Cox transformation 1.\n",
    "\n",
    "Let's try it out with the second Box Cox transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy & split the dataframe\n",
    "df5 = df.copy()\n",
    "df5 = remove_outliers(df5, in_columns=df5.select_dtypes(np.number).columns, \n",
    "                         skip_columns=['number of open complaints', 'number of policies',\n",
    "                         'months since policy inception', 'months since last claim']) \n",
    "X5, y5, X5_num, X5_cat = split_data(df5)\n",
    "\n",
    "# Box Cox transformation excludes monthly premium auto\n",
    "for column in X5_num:\n",
    "    # Select the columns with continuous data\n",
    "    if len(X5_num[column].unique()) > 500:\n",
    "        # Replace negative data with null values, then replace those with the mean\n",
    "        X5_num[column] = np.where(X5_num[column]<=0, np.nan, X5_num[column])        \n",
    "        X5_num[column] = X5_num[column].fillna(X5_num[column].mean())\n",
    "        X5_num[column], _ = stats.boxcox(X5_num[column])\n",
    "\n",
    "X5_num_norm = normalize_data(X5_num)\n",
    "cat5_encoded = encode_data(X5_cat)\n",
    "run_regression(X5_num_norm, cat5_encoded, y5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model performs the same with both Box Cox transformations as long as the outliers were removed beforehand."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
